---
title: "RHomework3"
author: "Sadiq Rahman"
date: "24/02/2021"
output: html_document
---


```{r message = FALSE}
library(tidyverse)
library(factoextra)
```

# 2 Stoop, standing up, or sitting down

```{r message = FALSE, warning = FALSE}
stroop <- read_csv("stroop_standing_data.csv")
```

The data in it's current form is *very* messy.
We can start by mutating reaction time to a numerical value, not a categorical value.
By doing so, we can omit all data where RT was not recorded (rt = FALSE). We cannot analyse reaction time is there are FALSE data.

```{r, warning = FALSE}
stroop <- mutate(stroop, rt = as.numeric(rt))
stroop <- filter(stroop, rt > 0)
```

Then, we omit all practice trials as these are not relevant for our analysis.

```{r}
stroop <- filter(stroop, phase != "practice")
```

Next, we omit all mistrials (correct = 999).

```{r}
stroop <- filter(stroop, correct < 2)
```

Finally, by changing the variable X11 to numeric (from logical) we can see that it is simply a copy of RT.
We can proceed by omitting the whole column as it is essentially a duplicate and is not unnecassary. We now have uncluttered, understandable data.

```{r}
stroop <- mutate(stroop, X11 = as.numeric(X11))
stroop <- stroop[,-11]
```

By grouping by phase and congruency, we can extract mean reaction times, as well as the proportion of correct trials in each group.

```{r message = FALSE}
stroop %>%
group_by(phase, congruency) %>%
summarise(
rt = mean(rt),
n = n(),
proportion = mean(correct)) %>%
glimpse() -> summary_stroop
```

As expected, we find that the incongruent condition (e.g., stimuli such as $\color{blue}{\text{red}}$) take longer to react to than the congruent ($\color{red}{\text{red}}$) and the baseline condition. At first glance at the numbers, there doesn't appear to be a significant
effect for phase or condition on reaction time or proportion correct.

```{r}
boxplot(rt ~ congruency, stroop)
```

The boxplot shows that on average, the reaction time in the congruent and the baseline condition are practically the same. The variance
for these two conditions are also very similar. The incongruent coondition shows the greatest reaction time, as expected. It also shows the greatest variance.

A linear model can determine whether there is a significant difference for phase on reaction time.

```{r}
stroop_phase <- lm(rt ~ phase, stroop)
summary(stroop_phase)
```

Model reveals no significant difference in reaction time between those standing and those sitting (*p* > 0.05).
What about the effect of congruency on reaction time?

```{r}
stroop_congruency <- lm(rt ~ congruency, stroop)
summary(stroop_congruency)
```

As expected, only the difference between the incongruent and baseline condition were significant. (*p* < .05)
Finally, We can then look at the influence on whether starting trials sitting or standing can have influence reaction time.

```{r}
stroop_condition <- lm(rt ~ condition, stroop)
summary(stroop_condition)
```

Participants showed a significantly lower reaction time if they started sitting (rt = 819) compared to participants who started standing (rt = 841; *p* < .05).

Linking this back to the original study which found a smaller stroop effect when participants performed the task standing (i.e, greater stroop effect when sitting; greater reaction time when sitting), the replication study found no significant difference in the stroop effect whether participants were standing or when they were sitting (*p* = 0.64)
The replication study did however, find a significant difference in the stroop effect depending on whether participants *started*
sitting down or standing up. It also found that those in the incongruent trials took significantly longer to react than those in the baseline and congruent condition (*p* < .05)

# 3 The dimensions of popular music

```{r, message=FALSE, warning=FALSE}
Spotify <- read_csv("spotify_cleaned.csv")
```

First we can start by removing all information that is not relevant to our replication. By referring to the article, we can see which variables they selected for their PCA.

```{r, message=FALSE, warning=FALSE}
Spotify <- select(Spotify, -time_signature, -X1, -"Track Name", -Artist, -Streams)
```

Now we can run the PCA.

```{r}
PCA <- prcomp(Spotify)
summary(PCA)
fviz_pca_var(PCA)
```

Like the original study, we find that 63% of the variance is being explained by the first dimension (Duration_sec), and an additional 35.5% of the variance is being explained by the second dimension (Tempo). ~99.3% of the variance is being explained by the first two dimensions.
The analysis was originally conducted to see what makes some music more popular than others. By breaking down songs into 24 attributes, we can see what qualites are found in the most popular songs. We can conclude that duration_sec and tempo is also two very important factors for what makes a song so popular. 

What happens when we standardise the variables? One problem is that the variables were not standardised in the original analysis, which could be why duration_sec is explaining majority of the variance (as well as tempo). We can standardise all the variable and rurun the PCA.

```{r message=FALSE, warning=FALSE} 
Spotify_s <- mutate(Spotify, 
valence = scale(valence),
acousticness = scale(acousticness),
loudness = scale(loudness),
energy = scale(energy),
danceability = scale(danceability),
tempo = scale(tempo),
duration_sec = scale(duration_sec),
key = scale(key), 
mode = scale(mode),
speechiness = scale(speechiness),
instrumentalness = scale(instrumentalness),
liveness = scale(liveness))
```

```{r}
PCA_s <- prcomp(Spotify_s)
summary(PCA_s)
fviz_pca_var(PCA_s)
```

We now observe much more variance attributed to different dimensions. The first dimension (predominantly Tempo) only explains 19.8% of the variance,whereas the second dimension (predominantly Loudness) explains 13.3%. To get around the same variance as before (~99%), we would need 11 dimensions. 






